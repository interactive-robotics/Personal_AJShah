{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', ['G', ['and', ['not', ['T0']], ['not', ['T1']], ['not', ['T2']], ['not', ['T3']], ['not', ['T4']]]], ['imp', ['P0'], ['F', ['W0']]], ['imp', ['P1'], ['F', ['W1']]], ['imp', ['P2'], ['F', ['W2']]], ['imp', ['P3'], ['F', ['W3']]], ['imp', ['P0'], ['U', ['not', ['W1']], ['W0']]], ['imp', ['P0'], ['U', ['not', ['W2']], ['W0']]], ['imp', ['P1'], ['U', ['not', ['W2']], ['W1']]]]\n"
     ]
    }
   ],
   "source": [
    "import FormulaTools as ft\n",
    "import Progression as prog\n",
    "from Constants import *\n",
    "import numpy as np\n",
    "\n",
    "PathToDataFile = ''\n",
    "SampleSignal = ImportSampleData(PathToDataFile)\n",
    "\n",
    "\n",
    "Formulas, Prob = ImportCandidateFormulas()\n",
    "idx = np.argsort(Prob)[::-1]\n",
    "Formulas = np.array(Formulas)\n",
    "Prob = np.array(Prob)\n",
    "Formulas = Formulas[idx]\n",
    "Prob = Prob[idx]\n",
    "formula = Formulas[0]\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now first lets verify that the syntax of the sampled formulas is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'AndOr')\n"
     ]
    }
   ],
   "source": [
    "print(ft.VerifyFormulaSyntax(formula))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check that the vocabulary of the formula is a subset of the signal vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula Vocabulary {'T4', 'P3', 'P2', 'T2', 'T3', 'W1', 'P0', 'W2', 'T0', 'P1', 'W0', 'W3', 'T1'}\n",
      "Signal predicates {'T4', 'P3', 'P2', 'T2', 'T3', 'W1', 'P0', 'W2', 'T0', 'P1', 'W0', 'W3', 'T1'}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('Formula Vocabulary', ft.GetVocabulary(formula, set()))\n",
    "print('Signal predicates', set(SampleSignal.keys()) - set(['length']))\n",
    "print(prog.VerifyVocabulary(formula, SampleSignal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate a slice of the labeling propositions at the first time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T4': False, 'P3': True, 'P2': True, 'T2': False, 'T3': False, 'W1': False, 'P0': True, 'W2': False, 'T0': False, 'P1': True, 'W0': False, 'W3': False, 'T1': False}\n"
     ]
    }
   ],
   "source": [
    "SignalSlice = ft.GetTraceSlice(SampleSignal,0)\n",
    "print(SignalSlice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The formulas have conditional predicates that make their effect felt from the first time step and are not relevant in the dynamic part of the task, so lets progress the formula by a single time step before beginning the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', ['G', ['and', ['not', ['T0']], ['not', ['T1']], ['not', ['T2']], ['not', ['T3']], ['not', ['T4']]]], ['F', ['W0']], ['F', ['W1']], ['F', ['W2']], ['F', ['W3']], ['U', ['not', ['W1']], ['W0']], ['U', ['not', ['W2']], ['W0']], ['U', ['not', ['W2']], ['W1']]]\n"
     ]
    }
   ],
   "source": [
    "progressed_formula = prog.ProgressSingleTimeStep(formula, SignalSlice)\n",
    "print(progressed_formula)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the progressed formula has a more limited vocabulary compared to the original formula and this is better for progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T0', 'T1', 'T2', 'T3', 'T4', 'W0', 'W1', 'W2', 'W3'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.GetVocabulary(progressed_formula, set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `FindAllProgressions` to evaluate all possible progressions of the given formula and a description of the graph of formulas given the truth assignments in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "progressions, edges = prog.FindAllProgressions(progressed_formula)\n",
    "states = dict([(v,k) for (k,v) in progressions.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as the LTL formulas were stored as nested lists, we have to convert them to json strings to use a dictionary to hash them. `progressions` is a dictionary where the keys represent all possible progressions of the original formula. The value stored at the key represents a unique integer index that can be used as a one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"and\", [\"G\", [\"and\", [\"not\", [\"T0\"]], [\"not\", [\"T1\"]], [\"not\", [\"T2\"]], [\"not\", [\"T3\"]], [\"not\", [\"T4\"]]]], [\"F\", [\"W0\"]], [\"F\", [\"W1\"]], [\"F\", [\"W2\"]], [\"F\", [\"W3\"]], [\"U\", [\"not\", [\"W1\"]], [\"W0\"]], [\"U\", [\"not\", [\"W2\"]], [\"W0\"]], [\"U\", [\"not\", [\"W2\"]], [\"W1\"]]]\n"
     ]
    }
   ],
   "source": [
    "key = list(progressions.keys())[0]\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`states` is the inverse map of the states to the LTL formula representing the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0]==key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`edges` is a tuple structure that represents the graph of transitions between the LTL formulas and the truth value assignments that cause that transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The source state/formula is:\n",
      " ['and', ['G', ['and', ['not', ['T0']], ['not', ['T1']], ['not', ['T2']], ['not', ['T3']], ['not', ['T4']]]], ['F', ['W0']], ['F', ['W1']], ['F', ['W2']], ['F', ['W3']], ['U', ['not', ['W1']], ['W0']], ['U', ['not', ['W2']], ['W0']], ['U', ['not', ['W2']], ['W1']]]\n",
      "\n",
      "\n",
      "With truth assignment: \n",
      "[{'T0': False, 'T1': False, 'T2': False, 'T3': False, 'T4': False, 'W0': True, 'W1': False, 'W2': False, 'W3': True}]\n",
      "\n",
      "\n",
      "The resulting formula is: \n",
      " ['and', ['G', ['and', ['not', ['T0']], ['not', ['T1']], ['not', ['T2']], ['not', ['T3']], ['not', ['T4']]]], ['F', ['W1']], ['F', ['W2']], ['U', ['not', ['W2']], ['W1']]]\n"
     ]
    }
   ],
   "source": [
    "edge = edges[5]\n",
    "print(f'The source state/formula is:\\n {edge[0]}\\n\\n')\n",
    "print(f'With truth assignment: \\n{edge[2]}\\n\\n')\n",
    "print(f'The resulting formula is: \\n {edge[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both 'W1' and 'W2' were completed simultaneously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
